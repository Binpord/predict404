\chapter{Обучение классификатора}

\section{Выбор модели}

Заметим, что пространство признаков имеет очень большую размерность. К тому же многие из признаков сильно взаимосвязаны с другими (действительно, доля досмотревших до 90 \% видео не может быть выше доли досмотревших до 50 \%). Если с размерностью можно справиться, например, воспользовавшись методом главных компонент \footcite{Pearson1901}, то избавиться от зависимости между признаками гораздо сложнее. В данной работе было принято решение использовать модели машинного обучения, основанные на решающих деревьях \footcite{LeoConsultant1984}. Это позволяет исключить из предобработки уменьшение размерности признаков, а также перестать беспокоиться о зависимостях в признаках. Однако решающие деревья в чистом виде используются редко из-за высокой чувствительности к значениям гиперпараметров и низкой обобщающей способностью модели. Однако решающие деревья показывают очень хорошие результаты, когда они используются в виде разных ансамблей.

В качестве базовой модели был выбран случайный лес \footcite{Ho}. Данный выбор обусловлен тем что метод зарекомендовал себя как неприхотливый алгоритм, который тем не менее показывает довольно высокие результаты практически во всех задачах. Также было замечено, что выборка в 100000 объектов не очень велика. Также важно понимать, что среди этих объектов только около 1 \% видеозаписей были размечены как неработающие. Таким образом выборка содержит довольно мало сигнала, который мы хотим детектировать. Поэтому в качестве дополнительной модели был выбран метод чрезвычайно случайных деревьев (extremely randomized trees) \footcite{Geurts2006}, который позволяет в некоторых случаях уменьшить разброс предсказаний за счет небольшого увеличения смещения предсказания. В качестве последней модели был выбран метод градиентного бустинга (gradient boosting) \footcite{Friedman2001} на решающих деревьях, как наиболее точной хотя и наименее неприхотливый алгоритм.

Численные эксперименты производились с помощью языка прогромирования Python \footcite{Python}. Реализации первых двух алгоритмов были взяты из библиотеки scikit-learn \footcite{scikit-learn}, реализация последнего была взята из библиотеки CatBoost \footcite{Prokhorenkova2017}.

\section{Обучение модели}

Для подбора гиперпараметров и получения оценки точности и полноты использовался сеточный поиск с оценкой точности и полноты с использованием 5-кратной перекрестной проверки. Для моделей random forest и extremely randomized trees подбиралось количество деревьев в ансамбле. Для классификатора CatBoost кроме того подбиралась максимальная глубина дерева.

Результаты сеточного поиска представлены в таблице \ref{tab:toloka_grid_search}, а также на рисунках \ref{fig:toloka_randomforest}, \ref{fig:toloka_extratrees} и \ref{fig:toloka_catboost}. При этом в таблице \ref{tab:toloka_grid_search} модели extremely randomized trees и классификатору из библиотеки CatBoost в таблице соответствуют по две строки каждому. Это сделано для того, чтобы показать метрики и для модели с наибольшей точностью, и для модели с наивысшей полнотой. Для модели random forest разница между точностью для этих двух классификаторов несущественна, поэтому представлены только значения метрик для модели с наивысшей полнотой.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% & Число деревьев & Глубина \\
        \hline
        RandomForestClassifier & 72.0 & 50.8 & 500 & \\
        \hline
        ExtraTreesClassifier & 74.3 & 47.0 & 1400 & \\
        \hline
        ExtraTreesClassifier & 73.9 & 47.2 & 1100 & \\
        \hline
        CatBoostClassifier & \textbf{80.3} & 51.4 & 650 & 3 \\
        \hline
        CatBoostClassifier & 77.5 & \textbf{53.2} & 500 & 4 \\
        \hline
    \end{tabular}
    \caption{Результаты сеточного поиска}
    \label{tab:toloka_grid_search}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_randomforest_precision.pdf}
    \includegraphics{../images/toloka_randomforest_recall.pdf}
    \caption{Результаты сеточного поиска для модели RandomForestClassifier}
    \label{fig:toloka_randomforest}
\end{figure}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_extratrees_precision.pdf}
    \includegraphics{../images/toloka_extratrees_recall.pdf}
    \caption{Результаты сеточного поиска для модели ExtraTreesClassifier}
    \label{fig:toloka_extratrees}
\end{figure}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_catboost_precision.pdf}
    \includegraphics{../images/toloka_catboost_recall.pdf}
    \caption{Результаты сеточного поиска для модели CatBoostClassifier}
    \label{fig:toloka_catboost}
\end{figure}

Как можно видеть, модель extremely randomized trees действительно смогла немного увеличить точность классификации по сравнению с результатами базовой модели. Однако при этом модель оказалась слегка более смещенной из-за чего снизилась полнота. Лучше всех себя показал классификатор из библиотеки CatBoost. Именно с использованием данного алгоритма была достигнута наилучшая в данном эксперименте точность классификации в 80.3 \%. При этом полнота классификации у данной модели оказалась выше, чем у моделей RandomForestClassifier и ExtraTreesClassifier. Наибольшей полноты классификации в данном эксперименте (51.4 \%) также удалось достичь именно классификатору из библиотеки CatBoost, правда, при других значениях гиперпараметров.

\section{Анализ модели}

После численного эксперимента был произведен анализ наилучшей модели. В результате этого анализа были выявлены две существенные закономерности. Во-первых не смотря на преобладающее количество признаков, полученных из времени просмотра, события плеера, а именно усредненные события старта и ошибки, обладают высоким весом в финальной модели. Вторым важным фактом, обнаруженным во время анализа модели, является то, что выборка содержит в себе заметную долю видеозаписей, неверно размеченных как работающие. Как выяснилось в дальнейшем, это вызвано спецификой работы сервиса Yandex Toloka, который склонен верить хорошо зарекомендовавшим себя пользователям в случае, если они размечают видеозапись, как работающую (в силу того, что достоверно известно, что неработающих видеозаписей всего около 1 \%).

Напомню, что изначальным желанием было избавиться или практически избавиться от влияния событий плеера на предсказание модели, так как, несмотря на аккуратность и информативность такого сигнала в целом, они доступны не для всех видеозаписей, а также характерный профиль событий различается от плеера к плееру. Тем не менее модель посчитала данные признаки информативными и смогла добиться достаточно высокой точности. В связи с этим было предложено добавить в данные идентификатор плеера, как категориальный признак, что позволило бы модели корректировать ожидаемый профиль событий в зависимости от их источника. Так как из всех используемых моделей с категориальными признаками умеет работать только CatBoost (для остальных моделей потребовалась бы дополнительная предобработка данных), было принято решение ограничиться им. Результаты эксперимента представлены в таблице \ref{tab:toloka_catboost_with_cat}, а также на рисунке \ref{fig:toloka_catboost_with_cat}.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% & Число деревьев & Глубина \\
        \hline
        CatBoostClassifier & \textbf{72.6} & 65.0 & 1250 & 2 \\
        \hline
        CatBoostClassifier & 71.3 & \textbf{68.1} & 800 & 5 \\
        \hline
    \end{tabular}
    \caption{Результаты эксперимента с категориальным признаком.}
    \label{tab:toloka_catboost_with_cat}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_catboost_with_cat_precision.pdf}
    \includegraphics{../images/toloka_catboost_with_cat_recall.pdf}
    \caption{Результаты эксперимента с категориальным признаком.}
    \label{fig:toloka_catboost_with_cat}
\end{figure}

Как можно видеть, точность классификации упала на 7.7 \% до 72.6 \%, однако полнота возросла на 14.9 \% и составила 68.1 \%. Это говорит скорее всего о переобучении модели на новый категориальный признак, то есть модель просто запомнила, что видеозаписи некоторых плееров чаще всего не работают и прекратила попытки честно их классифицировать.

\section{Одноплеерная модель}

Для решения проблемы неаккуратной разметки данных, было принято решение попробовать размечать выборку с помощью данных обхода. В таком случае мы получаем очень достоверный сигнал о том, какие видеозаписи не работали. Однако возникает обратная проблема: у нас нет достоверной информации о том, какие работали. Для решения данной проблемы был выбран следующий подход: известно, что среди видеозаписей, которые представлены на выдаче поиска, не работает примерно 1 \%. Исходя из этого, при составлении выборки мы считаем количество достоверно неработавших видео исходя из данных обхода и размечаем эти видеозаписи. Остальные видео сортируем в убывающем порядке по среднему времени просмотра и отбираем столько, чтобы баланс классов составлял 99 к 1. Таким образом мы получаем размеченную выборку большого размера, так как история обхода доступна за довольно длительный промежуток времени. Это позволяет ограничиться данными единственного плеера, что позволит модели в полной мере использовать данные событий плеера. Так как в результирующей выборке получилось около 1000000 объектов, время обучения модели стало занимать заметно большее время. Поэтому было принято решение ограничиться в данном эксперименте только хорошо зарекомендовавшим себя классификатором из библиотеки CatBoost. Результаты сеточного поиска представлены в таблице \ref{tab:model_factory} и на рисунке \ref{fig:model_factory}.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% & Число деревьев & Глубина \\
        \hline
        CatBoostClassifier & \textbf{89.3} & 51.4 & 1550 & 3 \\
        \hline
        CatBoostClassifier & 88.2 & \textbf{54.7} & 1850 & 5 \\
        \hline
    \end{tabular}
    \caption{Результаты сеточного поиска для модели обученной на данных обхода.}
    \label{tab:model_factory}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/model_factory_precision.pdf}
    \includegraphics{../images/model_factory_recall.pdf}
    \caption{Результаты сеточного поиска для модели обученной на данных обхода}
    \label{fig:model_factory}
\end{figure}

Эксперимент показал прирост точности классификации в 9.1 \%. Сама точность составила 89.3 \%, что является хорошим результатом учитывая природу данных и их зашумленность. При этом модель показала полноту, которая не существенно отличается от случая модели, обученной на данных размеченных с помощью сервиса Yandex Toloka. Наилучшая полнота, которая была достигнута в данном эксперименте (54.7 \%) и вовсе выше, чем в случае экспертной разметки данных.