\chapter{Обучение классификатора}

\section{Выбор модели}

Как было сказано ранее, пространство признаков имеет очень высокую размерность (154). К тому же многие из признаков сильно взаимосвязаны с другими (действительно, доля досмотревших до 90 \% видео не может быть выше доли досмотревших до 50 \%). Несмотря на то, что с этими недостатками можно было попытаться справиться с помощью методов понижения размерности, таких как метод главных компонент \cite{Pearson1901}, в данной работе было принято решение использовать модели машинного обучения, основанные на решающих деревьях. Это позволяет исключить из предобработки уменьшение размерности признаков, а также перестать беспокоиться о зависимостях в признаках.

В качестве базовой модели была выбрана модель random forest. Данный выбор обусловлен тем что модель зарекомендовала себя, как модель, которая показывает довольно высокие результаты практически во всех задачах. Также было замечено, что выборка в 101034 объекта не очень велика. Также важно понимать, что среди этих объектов только 1.36 \% видеозаписей были размечены как неработающие. Таким образом выборка содержит довольно мало сигнала, который мы хотим детектировать. Поэтому в качестве дополнительной модели была выбрана модель extremely randomized trees, которая позволяет в некоторых случаях уменьшить разброс предсказаний за счет небольшого увеличения смещения предсказания. В качестве последней модели был выбран метод gradient boosting на решающих деревьях, как потенциально наиболее точная модель из всех представленных.

Численные эксперименты производились с помощью языка прогромирования Python \cite{Python}. Реализации первых двух моделей были взяты из библиотеки scikit-learn \cite{scikit-learn}, реализация последней модели была взята из библиотеки CatBoost \cite{Prokhorenkova2017}.

\section{Обучение модели}

Для подбора гиперпараметров и получения оценки точности и полноты использовался сеточный поиск с оценкой точности и полноты с использованием 5-кратной перекрестной проверки. Для моделей random forest и extremely randomized trees подбиралось количество деревьев в ансамбле. Для классификатора CatBoost кроме того подбиралась максимальная глубина дерева.

Результаты сеточного поиска представлены в таблице \ref{tab:toloka_grid_search}. Графики зависимости точности и полноты от значений гиперпараметров представлены на рисунках \ref{fig:toloka_randomforest}, \ref{fig:toloka_extratrees} и \ref{fig:toloka_catboost}. При этом в таблице \ref{tab:toloka_grid_search} модели extremely randomized trees и классификатору из библиотеки CatBoost в таблице соответствуют по две строки каждому. Это сделано для того, чтобы показать метрики и для модели с наибольшей точностью, и для модели с наивысшей полнотой. Для модели random forest разница между точностью для этих двух классификаторов несущественна, поэтому представлены только значения метрик для модели с наивысшей полнотой.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% \\
        \hline
        RandomForestClassifier, 500 деревьев & 72.0 & 50.8 \\
        \hline
        ExtraTreesClassifier, 1400 деревьев & 74.3 & 47.0 \\
        \hline
        ExtraTreesClassifier, 1100 деревьев & 73.9 & 47.2 \\
        \hline
        CatBoostClassifier, 650 деревьев глубины 3 & \textbf{80.3} & 51.4 \\
        \hline
        CatBoostClassifier, 500 деревьев глубины 4 & 77.5 & \textbf{53.2} \\
        \hline
    \end{tabular}
    \caption{Результаты сеточного поиска}
    \label{tab:toloka_grid_search}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_randomforest_precision.pdf}
    \includegraphics{../images/toloka_randomforest_recall.pdf}
    \caption{Результаты сеточного поиска для модели RandomForestClassifier}
    \label{fig:toloka_randomforest}
\end{figure}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_extratrees_precision.pdf}
    \includegraphics{../images/toloka_extratrees_recall.pdf}
    \caption{Результаты сеточного поиска для модели ExtraTreesClassifier}
    \label{fig:toloka_extratrees}
\end{figure}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_catboost_precision.pdf}
    \includegraphics{../images/toloka_catboost_recall.pdf}
    \caption{Результаты сеточного поиска для модели CatBoostClassifier}
    \label{fig:toloka_catboost}
\end{figure}

Как можно видеть, модель extremely randomized trees действительно смогла немного увеличить точность классификации по сравнению с результатами базовой модели, однако при этом показала меньшую полноту. Лучше всех себя показал классификатор из библиотеки CatBoost. Именно с использованием данного алгоритма была достигнута наилучшая в данном эксперименте точность классификации в 80.3 \%. При этом полнота классификации у данной модели оказалась выше, чем у моделей RandomForestClassifier и ExtraTreesClassifier. Наибольшей полноты классификации в данном эксперименте (51.4 \%) также удалось достичь именно классификатору из библиотеки CatBoost, правда, при других значениях гиперпараметров.

\section{Анализ модели}

После численного эксперимента был произведен анализ наилучшей модели. В результате этого анализа были выявлено, что события плеера, а именно усредненные события старта и ошибки, обладают наибольшим весом в финальной модели. При этом несмотря на аккуратность и информативность такого сигнала в целом, события плеера доступны не для всех видеозаписей, а также характерный профиль событий различается от плеера к плееру. Это значит, что модель может давать сильно смещенные предсказания для некоторых плееров. В связи с этим было предложено добавить в данные идентификатор плеера, как категориальный признак, что позволило бы модели корректировать ожидаемый профиль событий в зависимости от их источника. В данном эксперименте было принято решение ограничиться только моделью, которая показала наилучший результат, то есть классификатором из библиотеки CatBoost. Результаты эксперимента представлены в таблице \ref{tab:toloka_catboost_with_cat}. Графики зависимости точности и полноты от значений гиперпараметров представлены на рисунке \ref{fig:toloka_catboost_with_cat}.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% \\
        \hline
        CatBoostClassifier, 1250 деревьев глубины 2 & \textbf{72.6} & 65.0 \\
        \hline
        CatBoostClassifier, 800 деревьев глубины 5 & 71.3 & \textbf{68.1} \\
        \hline
    \end{tabular}
    \caption{Результаты эксперимента с категориальным признаком.}
    \label{tab:toloka_catboost_with_cat}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/toloka_catboost_with_cat_precision.pdf}
    \includegraphics{../images/toloka_catboost_with_cat_recall.pdf}
    \caption{Результаты эксперимента с категориальным признаком.}
    \label{fig:toloka_catboost_with_cat}
\end{figure}

Как можно видеть, точность классификации упала на 7.7 процентных пункта до 72.6 \%, однако полнота возросла на 14.9 процентных пункта и составила 68.1 \%. Это говорит скорее всего о переобучении модели на новый категориальный признак, то есть модель просто запомнила, что видеозаписи некоторых плееров чаще всего не работают и прекратила попытки честно их классифицировать.

\section{Одноплеерная модель}

Так как добавление идентификатора плеера в вектор признаков не позволил увлеичить точность предсказания, было принято решение попробовать обучать отдельную модель для каждого плеера. Это позволило бы модели выучивать характерный для данного плеера профиль событий и использовать это для наиболее увеличения точности предсказания. В таком случае возникла проблема недостаточности данных в исходной выборке. Действительно, она содержит всего лишь 101034 объекта, которые более или менее равномерно распределены по 87 различным плеерам. Кроме того неработающих видео среди них всего лишь 1.36 \%. Таким образом данных из исходной выборки недостаточно, чтобы можно было обучить по отдельной модели для каждого плеера. Поэтому было принято решение попробовать размечать выборку с помощью данных истории обхода, который принимал решение о работоспособности видеозаписей. В таком случае мы получаем очень достоверный сигнал о том, какие видеозаписи не работали. Однако возникает обратная проблема: у нас нет достоверной информации о том, какие работали. Для решения данной проблемы был выбран следующий подход: известно, что среди видеозаписей, которые представлены на выдаче поиска, не работает примерно 1 \%. Исходя из этого, при составлении выборки мы считаем количество достоверно неработавших видео исходя из данных обхода и размечаем эти видеозаписи. Остальные видео сортируем в убывающем порядке по среднему времени просмотра и отбираем столько, чтобы баланс классов составлял 99 к 1. Таким образом мы получаем размеченную выборку большого размера, так как история обхода доступна за довольно длительный промежуток времени. В данном эксперименте также было принято решение ограничиться только классификатором из библиотеки CatBoost. Результаты сеточного поиска представлены в таблице \ref{tab:model_factory}. Графики зависимости точности и полноты от значений гиперпараметров представлены на рисунке \ref{fig:model_factory}.

\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        Модель & Точность, \% & Полнота, \% \\
        \hline
        CatBoostClassifier, 1550 деревьев глубины 3 & \textbf{89.3} & 51.4 \\
        \hline
        CatBoostClassifier, 1850 деревьев глубины 5 & 88.2 & \textbf{54.7} \\
        \hline
    \end{tabular}
    \caption{Результаты сеточного поиска для модели обученной на данных обхода.}
    \label{tab:model_factory}
\end{table}

\begin{figure}
    \centering
    \includegraphics{../images/model_factory_precision.pdf}
    \includegraphics{../images/model_factory_recall.pdf}
    \caption{Результаты сеточного поиска для модели обученной на данных обхода}
    \label{fig:model_factory}
\end{figure}

Эксперимент показал прирост точности классификации в 9.1 процентных пункта. Сама точность составила 89.3 \%. Полнота получившейся модели совпала с полнотой классификатора, обученного на данных размеченных с помощью сервиса Yandex Toloka. Наилучшая полнота, которая была достигнута в данном эксперименте (54.7 \%) и вовсе выше, чем в случае экспертной разметки данных.